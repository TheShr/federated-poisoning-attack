# Federated Learning with Data Poisoning (Label Flip Attack)

This repository demonstrates **Federated Learning (FL)** using the **Flower framework** on an **IoT Anomaly Detection Dataset**, including the impact of **label flipping data poisoning attacks** by malicious clients.

---

## ðŸ“Œ Project Overview

- Framework: **Flower (flwr)**
- Backend: **PyTorch**
- Learning Type: **Federated Learning (FedAvg)**
- Attack Type: **Label Flip Attack**
- Use Case: **IoT Anomaly Detection**

Each IoT device acts as an independent federated client.

---

## Dataset Structure

```text
Anomaly Detection Dataset/
â”œâ”€â”€ Danmini_Doorbell/
â”œâ”€â”€ Ecobee_Thermostat/
â”œâ”€â”€ Philips_B120N10_Baby_Monitor/
â”œâ”€â”€ Provision_PT_737E_Security_Camera/
â””â”€â”€ Provision_PT_838_Security_Camera/
Each folder represents one federated client with its own private local data.
```
## Federated Learning Configuration
Number of Clients: 5

Malicious Clients: 2

Aggregation Algorithm: FedAvg

Training Rounds: 10

Evaluation Metric: Accuracy

Data Poisoning (Label Flip Attack)
Malicious clients intentionally corrupt labels during training:

y = (y +1)%num_classes
This degrades the global modelâ€™s performance after aggregation.

## Project Structure
```text
.
â”œâ”€â”€ client.py        # Flower client logic
â”œâ”€â”€ server.py        # Federated server + FedAvg
â”œâ”€â”€ model.py         # Neural network model
â”œâ”€â”€ dataset.py       # Client-wise data loading
â”œâ”€â”€ utils.py         # Train & test functions
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
## How to Run
Install dependencies
pip install flwr torch torchvision matplotlib
Start federated simulation
python server.py
Output
Accuracy vs Federated Rounds plot

Initially, it will train normaly as poisoned = False (default)
To train on or poison 2 (custom) of the clients set poisoned = True on server.py

Expected Behavior
No attack: Accuracy steadily increases

With attack: Accuracy fluctuates or degrades

## Research Motivation
This project helps understand:

Security risks in Federated Learning

Effects of poisoned clients on global models

Why robust aggregation is needed



